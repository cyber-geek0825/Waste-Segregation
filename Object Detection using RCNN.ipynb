{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1aa5b2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import  transforms \n",
    "import torch\n",
    "from torch import no_grad\n",
    "import requests\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fd1b71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_box(pred_class, img, rect_th=2, text_size=0.5, text_th=2, download_image=False, img_name=\"img\"):\n",
    "    \"\"\"\n",
    "    draws box around each object \n",
    "    \n",
    "    predicted_classes: a list where each element contains a tuple that corresponds to information about the different objects; Each element includes a tuple with the class name, probability of belonging to that class and the coordinates of the bounding box corresponding to the object \n",
    "    image : frozen surface \n",
    "   \n",
    "    \"\"\"\n",
    "    image = (np.clip(cv2.cvtColor(np.clip(img.numpy().transpose((1, 2, 0)), 0, 1), cv2.COLOR_RGB2BGR), 0, 1) * 255).astype(np.uint8).copy()\n",
    "\n",
    "    for predicted_class in pred_class:\n",
    "      \n",
    "        label=predicted_class[0]\n",
    "        probability=predicted_class[1]\n",
    "        box=predicted_class[2]\n",
    "        t = round(box[0][0].tolist())\n",
    "        l = round(box[0][1].tolist())\n",
    "        r = round(box[1][0].tolist())\n",
    "        b = round(box[1][1].tolist())\n",
    "\n",
    "        # Giving brief information about rectange, class and probability.\n",
    "        from colorama import Fore\n",
    "        from colorama import Style\n",
    "        print(f\"\\nLabel: {Fore.GREEN}{label}{Style.RESET_ALL}\")\n",
    "        print(f\"Box coordinates: {t}, {l}, {r}, {b}\")\n",
    "        print(f\"Probability: {probability}\")\n",
    "\n",
    "        # Drawing rectangle and adding text on the picture based on their class and size.\n",
    "        cv2.rectangle(image, (t, l), (r, b), (0, 255, 0), rect_th)\n",
    "        cv2.rectangle(image, (t, l), (t+110, l+17), (255, 255, 255), -1)\n",
    "        cv2.putText(image, label, (t+10, l+12),  cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                  text_size, (0,255,0), thickness=text_th)\n",
    "        cv2.putText(image, label+\": \"+str(round(probability, 2)), \n",
    "                  (t+10, l+12),  cv2.FONT_HERSHEY_SIMPLEX, text_size, \n",
    "                  (0, 255, 0),thickness=text_th)\n",
    "\n",
    "        # Plotting image\n",
    "        image = np.array(image)\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "        if download_image:\n",
    "            plt.savefig(f'{img_name}.png')\n",
    "        else:\n",
    "            pass\n",
    "        plt.show()\n",
    "\n",
    "        del(img)\n",
    "        del(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "432721ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_RAM(image_=False):\n",
    "    global image, img, pred\n",
    "    torch.cuda.empty_cache()\n",
    "    del(img)\n",
    "    del(pred)\n",
    "    if image_:\n",
    "        image.close()\n",
    "        del(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ce00a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HOME\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HOME\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "model_ = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "model_.eval()\n",
    "\n",
    "for name, param in model_.named_parameters():\n",
    "    param.requires_grad = False\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6a29a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x):\n",
    "    with torch.no_grad():\n",
    "        yhat = model_(x)\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "548c7090",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Input, Conv2D, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.layers import GlobalMaxPooling2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "pred_model=load_model('res_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d827d644-f56b-43e0-a1d6-654dd2e15f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import serial\n",
    "import time\n",
    "port = 'COM5'  \n",
    "baud_rate = 9600\n",
    "arduino = serial.Serial(port, baud_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e220d658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368ms/step\n",
      "Prediction: Non-Biodegradable\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(1)  # 0 for the default camera, adjust if using a different camera\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    img = transform(frame)\n",
    "    pred = model([img])\n",
    "    try:\n",
    "        bounding_box=pred[0]['boxes'][0].tolist()\n",
    "        t, l, r, b = [round(x) for x in bounding_box]\n",
    "        img_plot=(np.clip(cv2.cvtColor(np.clip(img.numpy().transpose((1, 2, 0)), 0, 1), cv2.COLOR_RGB2BGR), 0, 1) * 255).astype(np.uint8)\n",
    "        img_plot=cv2.rectangle(img_plot, (t, l), (r, b), (0, 255, 0), 10)\n",
    "        target_size = (224, 224)  # Replace with your model's input size\n",
    "        resized_frame = cv2.resize(frame[l:b,t:r], target_size)\n",
    "        image_array = np.expand_dims(resized_frame, axis=0)\n",
    "        image_array = image_array / 255.0\n",
    "        predictions = pred_model.predict(image_array)\n",
    "        classes=['Non-Biodegradable','Organic','Recyclable']\n",
    "        prediction_class=classes[np.argmax(predictions)]\n",
    "        # cv2.putText(img_plot, prediction_class, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 2)\n",
    "        print(\"Prediction:\", prediction_class)\n",
    "        cv2.imshow('Detected Object', img_plot)\n",
    "\n",
    "        arduino.write(prediction_class.encode())\n",
    "        break\n",
    "    except:\n",
    "        print(\"\")\n",
    "    plt.show()\n",
    "    # Show the current frame for reference\n",
    "    cv2.imshow('Camera Feed', frame)\n",
    "\n",
    "    # Break the loop on 'q' key press\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the capture and close windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f9177ad-81ad-4e49-b2d7-b638d8c0c974",
   "metadata": {},
   "outputs": [],
   "source": [
    "arduino.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4391f1-6ccd-45b4-82e5-63be98b74313",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
